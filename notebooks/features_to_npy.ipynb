{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook creates features, such as CQTs and STFTs, for each track and stores them in a npy file format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = utils.load_csv(\"tracks\")\n",
    "train_tracks = tracks[tracks[\"set\", \"split\"] == \"training\"]\n",
    "validate_tracks = tracks[tracks[\"set\", \"split\"] == \"validation\"]\n",
    "test_tracks = tracks[tracks[\"set\", \"split\"] == \"test\"]\n",
    "del tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directory to store features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"data/features\"):\n",
    "    os.makedirs(\"data/features\")\n",
    "\n",
    "if not os.path.isdir(\"data/features/ids\"):\n",
    "    os.makedirs(\"data/features/ids\")\n",
    "\n",
    "if not os.path.isdir(\"data/features/cqt\"):\n",
    "    os.makedirs(\"data/features/cqt\")\n",
    "\n",
    "if not os.path.isdir(\"data/features/chroma_cqt\"):\n",
    "    os.makedirs(\"data/features/chroma_cqt\")\n",
    "    \n",
    "if not os.path.isdir(\"data/features/chroma_cens\"):\n",
    "    os.makedirs(\"data/features/chroma_cens\")\n",
    "\n",
    "if not os.path.isdir(\"data/features/stft\"):\n",
    "    os.makedirs(\"data/features/stft\")\n",
    "\n",
    "if not os.path.isdir(\"data/features/linear_stft\"):\n",
    "    os.makedirs(\"data/features/linear_stft\")\n",
    "\n",
    "if not os.path.isdir(\"data/features/mel_stft/\"):\n",
    "    os.makedirs(\"data/features/mel_stft/\")\n",
    "\n",
    "if not os.path.isdir(\"data/features/chroma_stft\"):\n",
    "    os.makedirs(\"data/features/chroma_stft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CQTs for each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids, test_cqts, test_failed_ids = utils.create_feature_array(test_tracks, \"cqt\")\n",
    "np.save(\"data/features/cqt/test_cqt.npy\", test_cqts)\n",
    "np.save(\"data/features/ids/test_ids.npy\", test_ids)\n",
    "np.save(\"data/features/ids/test_failed_ids.npy\", test_failed_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_ids, validate_cqts, validate_failed_ids = utils.create_feature_array(validate_tracks, \"cqt\")\n",
    "np.save(\"data/features/cqt/validate_cqt.npy\", validate_cqts)\n",
    "np.save(\"data/features/ids/validate_ids.npy\", validate_ids)\n",
    "np.save(\"data/features/ids/validate_failed_ids.npy\", validate_failed_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chunks = 8\n",
    "chunk_len = int(train_tracks.shape[0] / n_chunks)\n",
    "\n",
    "for chunk_i in range(n_chunks):\n",
    "    start_i = chunk_len * chunk_i\n",
    "    end_i = chunk_len * (chunk_i + 1) if chunk_i != (n_chunks - 1) else train_tracks.shape[0]\n",
    "    chunk = train_tracks.iloc[start_i:end_i]\n",
    "    train_ids, train_cqts, train_failed_ids = utils.create_feature_array(chunk, \"cqt\")\n",
    "    np.save(f\"data/features/cqt/train_cqt_{chunk_i}.npy\", train_cqts)\n",
    "    np.save(f\"data/features/ids/train_ids_{chunk_i}.npy\", train_ids)\n",
    "    np.save(f\"data/features/ids/train_failed_ids_{chunk_i}.npy\", train_failed_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Chroma CQT and CENS for each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_from_cqt(cqts_arr, type):\n",
    "    print(f\"Processing chroma_{type}\")\n",
    "    chromas = np.empty((0, 12, 640))\n",
    "    count = 0\n",
    "    start = time.time()\n",
    "    for cqt in cqts_arr:\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(f\"{utils.time_since(start)}, Processing {count} out of {cqts_arr.shape[0]}\")\n",
    "\n",
    "        if type == \"cqt\":\n",
    "            chroma = librosa.feature.chroma_cqt(C=cqt)\n",
    "        elif type == \"cens\":\n",
    "            chroma = librosa.feature.chroma_cens(C=cqt)\n",
    "        chromas = np.append(chromas, [chroma], axis=0)\n",
    "\n",
    "    return chromas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cqts = np.load(\"data/features/cqt/test_cqt.npy\")\n",
    "test_chroma_cqts = create_chroma_from_cqt(test_cqts, \"cqt\")\n",
    "test_chroma_cens = create_chroma_from_cqt(test_cqts, \"cens\")\n",
    "np.save(\"data/features/chroma_cqt/test_chroma_cqt.npy\", test_chroma_cqts)\n",
    "np.save(\"data/features/chroma_cens/test_chroma_cens.npy\", test_chroma_cens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_cqts = np.load(\"data/features/cqt/validate_cqt.npy\")\n",
    "validate_chroma_cqts = create_chroma_from_cqt(validate_cqts, \"cqt\")\n",
    "validate_chroma_cens = create_chroma_from_cqt(validate_cqts, \"cens\")\n",
    "np.save(\"data/features/chroma_cqt/validate_chroma_cqt.npy\", validate_chroma_cqts)\n",
    "np.save(\"data/features/chroma_cens/validate_chroma_cens.npy\", validate_chroma_cens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chunks = 8\n",
    "\n",
    "for i in range(n_chunks):\n",
    "    print(f\"Processing chunk {i}\")\n",
    "    train_cqts = np.load(f\"data/features/cqt/train_cqt_{i}.npy\")\n",
    "    train_chroma_cqts = create_chroma_from_cqt(train_cqts, \"cqt\")\n",
    "    train_chroma_cens = create_chroma_from_cqt(train_cqts, \"cens\")\n",
    "    np.save(f\"data/features/chroma_cqt/train_chroma_cqt_{i}.npy\", train_chroma_cqts)\n",
    "    np.save(f\"data/features/chroma_cens/train_chroma_cens_{i}.npy\", train_chroma_cens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids, test_stfts, test_failed_ids = utils.create_feature_array(test_tracks, \"stft\")\n",
    "np.save(\"data/features/stft/test_stft.npy\", test_stfts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_ids, validate_stfts, validate_failed_ids = utils.create_feature_array(validate_tracks, \"stft\")\n",
    "np.save(\"data/features/stft/validate_stft.npy\", validate_stfts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chunks = 8\n",
    "chunk_len = int(train_tracks.shape[0] / n_chunks)\n",
    "\n",
    "for chunk_i in range(7, n_chunks):\n",
    "    start_i = chunk_len * chunk_i\n",
    "    end_i = chunk_len * (chunk_i + 1) if chunk_i != (n_chunks - 1) else train_tracks.shape[0]\n",
    "    chunk = train_tracks.iloc[start_i:end_i]\n",
    "    _, train_stfts, _ = utils.create_feature_array(chunk, \"stft\")\n",
    "    np.save(f\"data/features/stft/train_stft_{chunk_i}.npy\", train_stfts)\n",
    "    del train_stfts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Linear and Mel Scale STFT in dB, and Chroma STFT\n",
    "* It breaks the STFT into chunks in order for this to run using only 8GB of memory, since the STFTs are big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_from_stft(stfts, type):\n",
    "    type_size = {\"linear\": (513, 640), \"mel\": (128, 640), \"chroma\": (12, 640)}\n",
    "    feature_arr = np.empty((0, type_size[type][0], type_size[type][1]))\n",
    "\n",
    "    count = 0\n",
    "    start = time.time()\n",
    "    for stft in stfts:\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(f\"{utils.time_since(start)}, Processing {count} out of {stfts.shape[0]}\")\n",
    "    \n",
    "        if type == \"linear\":\n",
    "            feature = librosa.amplitude_to_db(stft, ref=np.max)\n",
    "        elif type == \"mel\":\n",
    "            feature = librosa.feature.melspectrogram(S=stft**2, n_fft=1024, hop_length=1024)\n",
    "        elif type == \"chroma\":\n",
    "            feature = librosa.feature.chroma_stft(S=stft**2, n_fft=1024, hop_length=1024, n_chroma=12)\n",
    "        feature_arr = np.append(feature_arr, [feature], axis=0)\n",
    "        del feature\n",
    "    \n",
    "    return feature_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_stfts = np.load(\"data/features/stft/test_stft.npy\")\n",
    "\n",
    "for i in range(8):\n",
    "    print(f\"Creating chunk {i}...\")\n",
    "    chunk_stfts = test_stfts[i*100:(i + 1)*100]\n",
    "    np.save(f\"data/features/linear_stft/test_linear_stft_{i}.npy\", create_from_stft(chunk_stfts, \"linear\"))\n",
    "    np.save(f\"data/features/mel_stft/test_mel_stft_{i}.npy\", create_from_stft(chunk_stfts, \"mel\"))\n",
    "    np.save(f\"data/features/chroma_stft/test_chroma_stft_{i}.npy\", create_from_stft(chunk_stfts, \"chroma\"))\n",
    "    del chunk_stfts\n",
    "\n",
    "del test_stfts\n",
    "\n",
    "for type in [\"linear\", \"mel\", \"chroma\"]:\n",
    "    type_size = {\"linear\": (513, 640), \"mel\": (128, 640), \"chroma\": (12, 640)}\n",
    "    feature_arr = np.empty((0, type_size[type][0], type_size[type][1]))\n",
    "    for i in range(8):\n",
    "        print(f\"Getting chunk {i} for {type} STFT\")\n",
    "        feature_arr = np.append(feature_arr, np.load(f\"data/features/{type}_stft/test_{type}_stft_{i}.npy\"), axis=0)\n",
    "        os.remove(f\"data/features/{type}_stft/test_{type}_stft_{i}.npy\")\n",
    "    np.save(f\"data/features/{type}_stft/test_{type}_stft.npy\", feature_arr)\n",
    "    del feature_arr\n",
    "\n",
    "os.remove(\"data/features/stft/test_stft.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validate_stfts = np.load(\"data/features/stft/validate_stft.npy\")\n",
    "\n",
    "for i in range(8):\n",
    "    print(f\"Creating chunk {i}...\")\n",
    "    chunk_stfts = validate_stfts[i*100:(i + 1)*100]\n",
    "    np.save(f\"data/features/linear_stft/validate_linear_stft_{i}.npy\", create_from_stft(chunk_stfts, \"linear\"))\n",
    "    np.save(f\"data/features/mel_stft/validate_mel_stft_{i}.npy\", create_from_stft(chunk_stfts, \"mel\"))\n",
    "    np.save(f\"data/features/chroma_stft/validate_chroma_stft_{i}.npy\", create_from_stft(chunk_stfts, \"chroma\"))\n",
    "    del chunk_stfts\n",
    "\n",
    "del validate_stfts\n",
    "\n",
    "for type in [\"linear\", \"mel\", \"chroma\"]:\n",
    "    type_size = {\"linear\": (513, 640), \"mel\": (128, 640), \"chroma\": (12, 640)}\n",
    "    feature_arr = np.empty((0, type_size[type][0], type_size[type][1]))\n",
    "    for i in range(8):\n",
    "        print(f\"Getting chunk {i} for {type} STFT\")\n",
    "        feature_arr = np.append(feature_arr, np.load(f\"data/features/{type}_stft/validate_{type}_stft_{i}.npy\"), axis=0)\n",
    "        os.remove(f\"data/features/{type}_stft/validate_{type}_stft_{i}.npy\")\n",
    "    np.save(f\"data/features/{type}_stft/validate_{type}_stft.npy\", feature_arr)\n",
    "    del feature_arr\n",
    "\n",
    "os.remove(\"data/features/stft/validate_stft.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_chunks = 8\n",
    "\n",
    "for chunk in range(n_chunks):\n",
    "    print(f\"Processing large training chunk {chunk}\")\n",
    "    train_stfts = np.load(f\"data/features/stft/train_stft_{chunk}.npy\")\n",
    "\n",
    "    for i in range(8):\n",
    "        print(f\"Creating chunk {i}...\")\n",
    "        chunk_stfts = train_stfts[i*100:(i + 1)*100]\n",
    "        np.save(f\"data/features/linear_stft/train_linear_stft_{chunk}_{i}.npy\", create_from_stft(chunk_stfts, \"linear\"))\n",
    "        np.save(f\"data/features/mel_stft/train_mel_stft_{chunk}_{i}.npy\", create_from_stft(chunk_stfts, \"mel\"))\n",
    "        np.save(f\"data/features/chroma_stft/train_chroma_stft_{chunk}_{i}.npy\", create_from_stft(chunk_stfts, \"chroma\"))\n",
    "        del chunk_stfts\n",
    "\n",
    "    del train_stfts\n",
    "\n",
    "    for type in [\"linear\", \"mel\", \"chroma\"]:\n",
    "        type_size = {\"linear\": (513, 640), \"mel\": (128, 640), \"chroma\": (12, 640)}\n",
    "        feature_arr = np.empty((0, type_size[type][0], type_size[type][1]))\n",
    "        for i in range(8):\n",
    "            print(f\"Getting chunk {i} for {type} STFT\")\n",
    "            feature_arr = np.append(feature_arr, np.load(f\"data/features/{type}_stft/train_{type}_stft_{chunk}_{i}.npy\"), axis=0)\n",
    "            os.remove(f\"data/features/{type}_stft/train_{type}_stft_{chunk}_{i}.npy\")\n",
    "        np.save(f\"data/features/{type}_stft/train_{type}_stft_{chunk}.npy\", feature_arr)\n",
    "        del feature_arr\n",
    "\n",
    "    os.remove(f\"data/features/stft/train_stft_{chunk}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
