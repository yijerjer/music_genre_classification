{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `sklearn`'s Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "import ast\n",
    "\n",
    "tracks = utils.load_csv(\"tracks\")\n",
    "genres = utils.load_csv(\"genre\")\n",
    "features = utils.load_csv(\"features\")\n",
    "\n",
    "fma_small_ids = tracks.index\n",
    "features = features.loc[fma_small_ids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "* Scale the features such that they have a mean of 0 and variance of 1\n",
    "* Encode the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "\n",
    "genre_title_to_id = dict(zip(genres.title, genres.index))\n",
    "tracks[\"track\", \"genre_id\"] = [genre_title_to_id[title] for title in tracks[\"track\", \"genre_top\"]]\n",
    "\n",
    "scaler = StandardScaler().fit(features)\n",
    "scaled_features = scaler.transform(features)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "encoded_genre_ids = enc.fit_transform(tracks[\"track\", \"genre_id\"])\n",
    "\n",
    "all_ids = tracks.index\n",
    "ids_by_type = [tracks[tracks[\"set\", \"split\"] == type].index for type in [\"training\", \"validation\", \"test\"]]\n",
    "train_ids, validate_ids, test_ids = ids_by_type\n",
    "idxs_by_type = [[tracks.index.get_loc(id) for id in ids] for ids in ids_by_type]\n",
    "train_idxs, validate_idxs, test_idxs = idxs_by_type\n",
    "\n",
    "X_train, X_validate, X_test = [scaled_features[idxs] for idxs in idxs_by_type]\n",
    "y_train, y_validate, y_test = [encoded_genre_ids[idxs] for idxs in idxs_by_type]\n",
    "\n",
    "y_test_binarize = label_binarize(y_test, classes=range(len(enc.classes_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the features data\n",
    "* Below is t-SNE plot obtained by embedding the >500 features into 2 dimensions.\n",
    "* The genres are generally quite dispersed and do not form clusters of a single genre.\n",
    "* There are some general trends, for example Folk (purple) can be seen to tend to the right of the plot, or Rock (green) tends to the lower half of the plot. However, these trends are not exactly that obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embedded_features = TSNE(n_components=2).fit_transform(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'genre_ids' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-960a9a7d1766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgenre_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgenre_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgenre_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_tracks_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded_tracks_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenre_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genre_ids' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(10, 10))\n",
    "genre_ids = tracks[\"track\", \"genre_id\"]\n",
    "\n",
    "for genre_id in enc.classes_:\n",
    "    idxs = [i for i, id in enumerate(genre_ids) if id == genre_id]\n",
    "    axs.scatter(embedded_tracks_features[genre_indices, 0], embedded_tracks_features[genre_indices, 1], label=genres.loc[genre_id][\"title\"], s=4)\n",
    "\n",
    "axs.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Genre \n",
    "* Classifiers then can be used:\n",
    "    * linear_model - LogisticRegression, RidgeClassifierCV\n",
    "    * svm - LinearSVC, SVC\n",
    "    * ensemble - RandomForestClassifier, AdaBoostClassfier, GradientBoostingClassifier\n",
    "    * naive_bayes - GaussianNB\n",
    "    * discriminant_analysis - LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis \n",
    "    * multiclass - OneVsRestClassifier\n",
    "    * neighbors - KNeighborsClassifier\n",
    "    * neural_network - MLPClassifier\n",
    "* Attempted to use `GridSearchCV` to search for better parameters for the classifiers. However, found that the accuracy remained in regions +-0.03 of its original value.\n",
    "* The scores and ROC curves below show that SVM, LDA and MLP classifiers work well here\n",
    "* Note that the accuracy score here is a valid metric to determine the success of the classifier, since the distribution across all genres are balanced. Note that the score of >0.5 already shows that there are features that does correlate with genre, given that a null hypothesis would give a score of 0.125 (1/8) since there are 8 genres.\n",
    "* Obtaining the feature importances of the RandomForestClassifier shows relatively equal importances across all features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "classifiers = {\n",
    "    \"LR\": LogisticRegression(), \"RC\": RidgeClassifier(),\n",
    "    \"LSVM\": LinearSVC(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"RFC\": RandomForestClassifier(), \"ABC\": AdaBoostClassifier(),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"LDA\": LinearDiscriminantAnalysis(), \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "    \"OvRC\": OneVsRestClassifier(LogisticRegression()),\n",
    "    \"KNC\": KNeighborsClassifier(),\n",
    "    \"MLP\": MLPClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    start = time.time()\n",
    "    print(f\"\\n ****** CLASSIFYING {name} ******\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(f\"TIME TAKEN: {int((end - start) / 60)} min {round((end - start) % 60, 2)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_genres = len(enc.classes_)\n",
    "score = dict()\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "confusion_mats = dict() \n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    score[name] = clf.score(X_test, y_test)\n",
    "    fpr[name] = dict()\n",
    "    tpr[name] = dict()\n",
    "    confusion_mats[name] = np.zeros((n_genres, n_genres))\n",
    "\n",
    "    for i, genre_id in enumerate(enc.classes_):\n",
    "        if name in [\"LSVM\", \"SVM\", \"RC\"]:\n",
    "            y_proba = classifiers[name].decision_function(X_test)\n",
    "        else:\n",
    "            y_proba = classifiers[name].predict_proba(X_test)\n",
    "        fpr[name][i], tpr[name][i], _ = metrics.roc_curve(y_test_binarize[:, i], y_proba[:, i])\n",
    "\n",
    "        y_predict = y_proba.argmax(axis=1)\n",
    "        genre_idxs = np.where(y_test == i)[0]\n",
    "        confusion_row_i = np.array([(y_predict[genre_idxs] == n).sum() for n in range(n_genres)])\n",
    "        confusion_mats[name][i] = confusion_row_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n",
    "\n",
    "for idx, (name, clf) in enumerate(classifiers.items()):\n",
    "    for i, genre_id in enumerate(enc.classes_):\n",
    "        axs[int(idx / 4)][idx % 4].plot(fpr[name][i], tpr[name][i], label=genres.loc[genre_id][\"title\"])\n",
    "    \n",
    "    axs[int(idx / 4)][idx % 4].set_title(f\"{name}, test accuracy = {round(score[name], 3)}\")\n",
    "    axs[int(idx / 4)][idx % 4].legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n",
    "n_genres = len(enc.classes_)\n",
    "relevant_genres = genres.loc[enc.classes_][\"title\"].tolist()\n",
    "\n",
    "for idx, (name, clf) in enumerate(classifiers.items()):\n",
    "    curr_axs = axs[int(idx / 4)][idx % 4] \n",
    "    for i, genre_id in enumerate(enc.classes_):\n",
    "        curr_axs.imshow(confusion_mats[name])\n",
    "\n",
    "        curr_axs.set_xticks(np.arange(n_genres))\n",
    "        curr_axs.set_xticklabels(labels=relevant_genres, rotation=\"vertical\")\n",
    "        curr_axs.set_yticks(np.arange(n_genres))\n",
    "        curr_axs.set_yticklabels(labels=relevant_genres)\n",
    "        for i in range(n_genres):\n",
    "            for j in range(n_genres):\n",
    "                curr_axs.text(j, i, int(confusion_mats[name][i][j]), va=\"center\", ha=\"center\", color='w')\n",
    "\n",
    "    curr_axs.set_title(f\"{name}, test accuracy = {round(score[name], 3)}\")\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}